---
nodes:
  # - address: 172.30.1.38
  #   user: linuxboot
  #   role:
  #   - worker
  #   ssh_key_path: /home/platform/.ssh/octopus-admin.pem
  #   port: 22
  #   labels:
  #     app: ingress
  #     vlan: "50"
  - address: bdgpu.os
    user: platform
    role:
    - worker
    # ssh_key_path: /home/platform/.ssh/octopus-admin.pem
    port: 22
    labels:
      vlan: "50"
  - address: osv7smi14c.mgt.os
    user: platform
    role:
    - controlplane
    - etcd
    - worker
    port: 22
    labels:
      app: ingress
      vlan: "50"
  - address: osv7smi14a.mgt.os
    user: platform
    role:
    - controlplane
    - etcd
    - worker
    port: 22
    labels:
      vlan: "50"
  - address: osv7smi16c.mgt.os
    user: platform
    role:
    - controlplane
    - etcd
    - worker
    port: 22
    labels:
      app: ingress
      vlan: "50"
  # - address: osv7smi14d.mgt.os
  #   user: platform
  #   role:
  #   - worker
  #   port: 22
  #   labels:
  #     vlan: "50"
  # - address: osv7smi14b.mgt.os
  #   user: platform
  #   role:
  #   - worker
  #   port: 22
  #   labels:
  #     vlan: "50"
  - address: osv7smi16a.mgt.os
    user: platform
    role:
    - worker
    port: 22
    labels:
      vlan: "50"
  # - address: osv7smi18c.mgt.os
  #   user: platform
  #   role:
  #   - worker
  #   port: 22
  #   labels:
  #     vlan: "50"
  # - address: osv7smi20c.mgt.os
  #   user: platform
  #   role:
  #   - worker
  #   # ssh_key_path: /home/platform/.ssh/octopus-admin.pem
  #   port: 22
  #   labels:
  #     vlan: "50"
  - address: kouda.os
    user: platform
    role:
    - worker
    port: 22
    labels:
      gpu: true
      gpu-type: NVIDIA_TITAN_X
      vlan: "55"
services:
  etcd:
  kube-api:
    service_cluster_ip_range: 10.233.0.0/18
    pod_security_policy: false
    extra_args:
      v: 4
    # image: rancher/k8s:v1.9.5-rancher1-1
  kube-controller:
    cluster_cidr: 10.233.64.0/18
    service_cluster_ip_range: 10.233.0.0/18
    # image: rancher/k8s:v1.9.5-rancher1-1
  scheduler:
    # image: rancher/k8s:v1.9.5-rancher1-1
  kubelet:
    cluster_domain: gezora-osv.os
    cluster_dns_server: 10.233.0.3
    infra_container_image: gcr.io/google_containers/pause-amd64:3.0
    # extra_args: {"feature-gates": "Accelerators=true"} #for k8s 1.7 and less... but working for 1.8 too somehow
    extra_args: { feature-gates: "DevicePlugins=true"}
    # image: rancher/k8s:v1.9.5-rancher1-1
  kubeproxy:
    # image: rancher/k8s:v1.9.5-rancher1-1

authentication:
  strategy: x509

# all addon manifests MUST specify a namespace
addons: |-
    ---
    apiVersion: v1
    kind: Pod
    metadata:
      name: ingress-nginx
      namespace: default
    spec:
      containers:
      - name: ingress-nginx
        image: nginx
        ports:
        - containerPort: 80

# Note that addons don't support upgrades today
addons_include:
# # ROOK
#     - https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/rook-operator.yaml
# #    - https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/rook-cluster.yaml
#     - ./rook-cluster.yml
# # GPU
    # - https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.10/nvidia-device-plugin.yml
# # MetalLB
# #   - ./metallb.yml
# #   _ ./configmap.yml


# If set to true, rke won't fail when unsupported Docker version is found
ignore_docker_version: true
kubernetes_version: v1.10.1

system_images:
  etcd: rancher/etcd:v3.0.17
  # kubernetes: rancher/k8s:v1.9.5-rancher1-1
  kubernetes: rancher/hyperkube:v1.10.1 # overrides the kubernetes_version value
  alpine: rancher/rke-tools:v0.1.5
  nginx_proxy: rancher/rke-tools:v0.1.5
  cert_downloader: rancher/rke-tools:v0.1.5
  kubernetes_services_sidecar: rancher/rke-tools:v0.1.5
  kubedns: rancher/k8s-dns-kube-dns-amd64:1.14.8
  dnsmasq: rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.8
  kubedns_sidecar: rancher/k8s-dns-sidecar-amd64:1.14.8
  kubedns_autoscaler: rancher/cluster-proportional-autoscaler-amd64:1.0.0
  # flannel: rancher/coreos-flannel:v0.9.1
  # flannel_cni: rancher/coreos-flannel-cni:v0.2.0
  # canal_node: rancher/calico-node:v3.1.1
  # canal_cni: rancher/calico-cni:v3.1.1
  # canal_node: rancher/calico-node:v2.6.2
  # canal_cni: rancher/calico-cni:v1.11.0
  # canal_node: rancher/calico-node:v3.0.2
  # canal_cni: rancher/calico-cni:v2.0.0
  # canal_flannel: rancher/coreos-flannel:v0.9.1


network:
  plugin: canal
  options:
    canal_node_image: rancher/calico-node:v3.1.1
    canal_cni_image: rancher/calico-cni:v3.1.1
    canal_flannel_image: rancher/coreos-flannel:v0.9.1

ssh_key_path: ~/.ssh/octopus-admin.pem
ssh_agent_auth: false

# Kubernetes authorization mode
# Use `mode: rbac` to enable RBAC
# Use `mode: none` to disable authorization
authorization:
  mode: rbac



# List of registry credentials, if you are using a Docker Hub registry,
# you can omit the `url` or set it to `docker.io`
private_registries:
  - url: docker.io
    # user: Username
    # password: password

# Currently only nginx ingress provider is supported.
# To disable ingress controller, set `provider: none`
# To enable ingress on specific nodes, use the node_selector, eg:
# nodes:
#   - address: example.com
#     user: ubuntu
#     role:
#     - role
#     hostname_override: node3
#     internal_address: 192.168.1.6
#     labels:
#       app: ingress
#
ingress:
  provider: nginx
  node_selector:
    app: ingress